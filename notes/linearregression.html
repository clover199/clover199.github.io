<!DOCTYPE html>
<html lang="en-US">

  <head>
    <title>Linear Regression - Emma's notes</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <!-- mobile friendly -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!--styles-->
    <link rel="stylesheet" href="../css/notes.css">
    <!--icons-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <!-- MathJax for math display -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: {
          scale: 90
        }
      });
    </script>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
  </head>

  <body>

  <header> </header>

  <nav>
    <a href="index.html">Home</a>
  </nav>

  <main>
    <div class="col-3 col-m-4 col-mm-6">
      <strong>Steps for fitting a model</strong></br>
      (1) Propose a model in terms of response variable, explanatory variables and residual variables.</br>
      (2) Specify/define a criterion for judging different estimators.</br>
      (3) Characterize the best estimator and apply it to the given data.</br>
      (4) Check the assumptions in (1).</br>
      (5) If necessary modify model and/or assumptions and go to (1).</br>
    </div>
    <div class="col-3 col-m-4 col-mm-6">
      <strong>Least Squares</strong></br>
      minimizes residual sum of square (RSS)</br>
      $$ \mathbf{Y} = \mathbf{X} \beta + \epsilon$$
      \(\mathbf{X}\): \(n\times p\)data matrix with \(n\) samples and \(p\) features.</br>
      If intercept is included, the first column is all ones.</br>
      \(\mathbf{Y}\): \(n\times1\) response variable.</br>
      \(\epsilon\): residual (error) variable with covariance matrix \(\Sigma\).</br>
      <em>Ordinary Least Squares (OLS)</em>: \(\Sigma=\sigma^2\mathbf{I}\)
      $$ \hat{\beta} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$$
      <em>Generalized Least Squares (GLS)</em>:
      $$ \hat{\beta} = (\mathbf{X}^T\Sigma^{-1}\mathbf{X})^{-1}\mathbf{X}^T\Sigma^{-1}\mathbf{Y}$$
    </div>
    <div class="col-3 col-m-4 col-mm-6">
      <strong>Gauss-Markov Theorem</strong></br>
      <em>assumptions</em>:</br>
      linear relationship</br>
      zero mean, constant variance, uncorrelated residuals</br>
      <em>theorem</em>:</br>
      Under the Gauss-Markov assumptions, the OLS estimator has the smallest (Best) variance among all Linear Unbiased
      Estimators (BLUE).</br>
      <em>Generalization</em>:</br>
      GLS is still BLUE.</br>
    </div>
    <div class="col-3 col-m-4 col-mm-6">
    </div>
  </main>

  <footer>
    <ul>
      <li>CS440/ECE448 Artificial Intelligence by <a href="http://slazebni.cs.illinois.edu/"> Svetlana Lazebnik</a>.</li>
    </ul>
  </footer>
  </body>

</html>
